#!/usr/bin/env python

"""
@package mi.dataset.parser.zplsc_b
@file marine-integrations/mi/dataset/parser/zplsc_b.py
@author Ronald Ronquillo & Richard Han
@brief Parser for the zplsc_b dataset driver

This file contains code for the zplsc_b parser to produce data particles and echogram plots.

The Simrad EK60 scientific echo sounder supports the *.raw file format.
The *.raw file may contain one or more of the following datagram types:
Configuration, NMEA, Annotation, Sample.

Every *.raw file begins with a configuration datagram. A second configuration datagram
within the file is illegal. The data content of the Configuration datagram of an already
existing file cannot be altered from the EK60. NMEA, Annotation and Sample datagrams
constitute the remaining file content. These datagrams are written to the *.raw file in the
order that they are generated by the EK60. Note: Strictly sequential time tags are not guaranteed.

A data particle is produced from metadata contained in the first ping of the series.
The metadata and echogram plots are extracted from the Sample datagram portion of the *.raw file.


Release notes:

Initial Release
"""

__author__ = 'Ronald Ronquillo'
__license__ = 'Apache 2.0'


import calendar
import ntplib
import re
import os
import numpy as np
from multiprocessing import Process
from datetime import datetime, timedelta
from struct import unpack
from collections import defaultdict

from mi.dataset.dataset_parser import SimpleParser
from mi.core.common import BaseEnum
from mi.core.exceptions import RecoverableSampleException
from mi.core.instrument.data_particle import DataParticle
from mi.core.log import get_logging_metaclass
from mi.logging import log

from mi.dataset.parser.zplsc_echogram import SAMPLE_MATCHER, LENGTH_SIZE, DATAGRAM_HEADER_SIZE, \
    CONFIG_HEADER_SIZE, CONFIG_TRANSDUCER_SIZE,\
    generate_plots, read_datagram_header, read_config_header, read_config_transducer


class ZplscBParticleKey(BaseEnum):
    """
    Class that defines fields that need to be extracted from the data
    """
    FILE_TIME = "zplsc_timestamp"               # raw file timestamp
    FILE_PATH = "filepath"                      # output echogram plot .png/s path and filename
    CHANNEL = "zplsc_channel"
    TRANSDUCER_DEPTH = "zplsc_transducer_depth" # five digit floating point number (%.5f, in meters)
    FREQUENCY = "zplsc_frequency"               # six digit fixed point integer (in Hz)
    TRANSMIT_POWER = "zplsc_transmit_power"     # three digit fixed point integer (in Watts)
    PULSE_LENGTH = "zplsc_pulse_length"         # six digit floating point number (%.6f, in seconds)
    BANDWIDTH = "zplsc_bandwidth"               # five digit floating point number (%.5f in Hz)
    SAMPLE_INTERVAL = "zplsc_sample_interval"   # six digit floating point number (%.6f, in seconds)
    SOUND_VELOCITY = "zplsc_sound_velocity"     # five digit floating point number (%.5f, in m/s)
    ABSORPTION_COEF = "zplsc_absorption_coeff"  # four digit floating point number (%.4f, dB/m)
    TEMPERATURE = "zplsc_temperature"           # three digit floating point number (%.3f, in degC)


# The following is used for _build_parsed_values() and defined as below:
# (parameter name, encoding function)
METADATA_ENCODING_RULES = [
    (ZplscBParticleKey.FILE_TIME,           str),
    (ZplscBParticleKey.FILE_PATH,           lambda x: [str(y) for y in x]),
    (ZplscBParticleKey.CHANNEL,             lambda x: [int(y) for y in x]),
    (ZplscBParticleKey.TRANSDUCER_DEPTH,    lambda x: [float(y) for y in x]),
    (ZplscBParticleKey.FREQUENCY,           lambda x: [float(y) for y in x]),
    (ZplscBParticleKey.TRANSMIT_POWER,      lambda x: [float(y) for y in x]),
    (ZplscBParticleKey.PULSE_LENGTH,        lambda x: [float(y) for y in x]),
    (ZplscBParticleKey.BANDWIDTH,           lambda x: [float(y) for y in x]),
    (ZplscBParticleKey.SAMPLE_INTERVAL,     lambda x: [float(y) for y in x]),
    (ZplscBParticleKey.SOUND_VELOCITY,      lambda x: [float(y) for y in x]),
    (ZplscBParticleKey.ABSORPTION_COEF,     lambda x: [float(y) for y in x]),
    (ZplscBParticleKey.TEMPERATURE,         lambda x: [float(y) for y in x])
]

# Numpy data type object for unpacking the Sample datagram including the header from binary *.raw
sample_dtype = np.dtype([('length1', 'i4'),                 # 4 byte int (long)
                      # DatagramHeader
                      ('datagram_type', 'a4'),              # 4 byte string
                      ('low_date_time', 'i4'),              # 4 byte int (long)
                      ('high_date_time', 'i4'),             # 4 byte int (long)
                      # SampleDatagram
                      ('channel_number', 'i2'),             # 2 byte int (short)
                      ('mode', 'i2'),                       # 2 byte int (short)
                      ('transducer_depth', 'f4'),           # 4 byte float
                      ('frequency', 'f4'),                  # 4 byte float
                      ('transmit_power', 'f4'),             # 4 byte float
                      ('pulse_length', 'f4'),               # 4 byte float
                      ('bandwidth', 'f4'),                  # 4 byte float
                      ('sample_interval', 'f4'),            # 4 byte float
                      ('sound_velocity', 'f4'),             # 4 byte float
                      ('absorption_coefficient', 'f4'),     # 4 byte float
                      ('heave', 'f4'),                      # 4 byte float
                      ('roll', 'f4'),                       # 4 byte float
                      ('pitch', 'f4'),                      # 4 byte float
                      ('temperature', 'f4'),                # 4 byte float
                      ('trawl_upper_depth_valid', 'i2'),    # 2 byte int (short)
                      ('trawl_opening_valid', 'i2'),        # 2 byte int (short)
                      ('trawl_upper_depth', 'f4'),          # 4 byte float
                      ('trawl_opening', 'f4'),              # 4 byte float
                      ('offset', 'i4'),                     # 4 byte int (long)
                      ('count', 'i4')])                     # 4 byte int (long)
sample_dtype = sample_dtype.newbyteorder('<')


GET_CONFIG_TRANSDUCER = False   # Optional data flag: not currently used
BLOCK_SIZE = 1024*4             # Block size read in from binary file to search for token

# ZPLSC EK 60 *.raw filename timestamp format
# ei. OOI-D20141211-T214622.raw
TIMESTAMP_FORMAT = "%Y%m%d%H%M%S"

# Regex to extract the timestamp from the *.raw filename (path/to/OOI-DYYYYmmdd-THHMMSS.raw)
FILE_NAME_MATCHER = re.compile(
    r'.+-D(?P<Date>(\d{4})(\d{2})(\d{2}))-T(?P<Time>\d{2}\d{2}\d{2})\.raw')


class DataParticleType(BaseEnum):
    """
    Class that defines the data particles generated from the zplsc_b data
    """
    SAMPLE = 'zplsc_b_metadata'  # instrument data particle


class ZplscBInstrumentDataParticle(DataParticle):
    """
    Class for generating the zplsc_b_instrument data particle.
    """

    _data_particle_type = DataParticleType.SAMPLE

    def _build_parsed_values(self):
        """
        Build parsed values for Instrument Data Particle.
        """

        # Generate a particle by calling encode_value for each entry
        # in the Instrument Particle Mapping table,
        # where each entry is a tuple containing the particle field name
        # and a function to use for data conversion.

        return [self._encode_value(name, self.raw_data[name], function)
                for name, function in METADATA_ENCODING_RULES]


class ZplscBParser(SimpleParser):
    """
    Parser for zplsc_b *.raw files
    """

    __metaclass__ = get_logging_metaclass(log_level='debug')

    def __init__(self, config, stream_handle, exception_callback, output_file_path):
        """
        Initialize the zplsc_b parser, which does not use state or the chunker
        and sieve functions.
        @param config: The parser configuration dictionary
        @param stream_handle: The stream handle of the file to parse
        @param exception_callback: The callback to use when an exception occurs
        @param output_file_path: The location to output the echogram plot .png files
        """

        self.output_file_path = output_file_path

        super(ZplscBParser, self).__init__(config, stream_handle, exception_callback)

    def recov_exception_callback(self, message):
        log.warn(message)
        self._exception_callback(RecoverableSampleException(message))

    def parse_file(self):
        """
        Parse the *.raw file.
        """

        # Extract the file time from the file name
        input_file_name = self._stream_handle.name
        (filepath, filename) = os.path.split(input_file_name)

        # tuple contains the string before the '.', the '.', and the 'raw' string
        outfile = filename.rpartition('.')[0]

        match = FILE_NAME_MATCHER.match(input_file_name)
        if match:
            file_time = match.group('Date') + match.group('Time')
            rel_file_path = os.path.join(*match.groups()[1:-1])
            full_file_path = os.path.join(self.output_file_path, rel_file_path)
            if not os.path.exists(full_file_path):
                os.makedirs(full_file_path)
        else:
            file_time = ""
            rel_file_path = ""
            # Files retrieved from the instrument should always match the timestamp naming convention
            self.recov_exception_callback("Unable to extract file time from input file name: %s."
                                          "Expected format *-DYYYYmmdd-THHMMSS.raw" % input_file_name)

        # Read binary file a block at a time
        raw = self._stream_handle.read(BLOCK_SIZE)

        # Set starting byte
        byte_cnt = 0

        # Read the configuration datagram, output at the beginning of the file
        length1, = unpack('<l', raw[byte_cnt:byte_cnt+LENGTH_SIZE])
        byte_cnt += LENGTH_SIZE

        # Configuration datagram header
        datagram_header = read_datagram_header(raw[byte_cnt:byte_cnt+DATAGRAM_HEADER_SIZE])
        byte_cnt += DATAGRAM_HEADER_SIZE

        # Configuration: header
        config_header = read_config_header(raw[byte_cnt:byte_cnt+CONFIG_HEADER_SIZE])
        byte_cnt += CONFIG_HEADER_SIZE

        transducer_count = config_header['transducer_count']

        if GET_CONFIG_TRANSDUCER:
            td_gain = {}
            td_gain_table = {}
            td_pulse_length_table = {}
            td_phi_equiv_beam_angle = {}

            # Configuration: transducers (1 to 7 max)
            for i in xrange(1, transducer_count+1):
                config_transducer = read_config_transducer(
                    raw[byte_cnt:byte_cnt+CONFIG_TRANSDUCER_SIZE])

                # Example data that one might need for various calculations later on
                td_gain[i] = config_transducer['gain']
                td_gain_table[i] = config_transducer['gain_table']
                td_pulse_length_table[i] = config_transducer['pulse_length_table']
                td_phi_equiv_beam_angle[i] = config_transducer['equiv_beam_angle']

        byte_cnt += CONFIG_TRANSDUCER_SIZE * transducer_count

        # Compare length1 (from beginning of datagram) to length2 (from the end of datagram) to
        # the actual number of bytes read. A mismatch can indicate an invalid, corrupt, misaligned,
        # or missing configuration datagram or a reverse byte order binary data file.
        # A bad/missing configuration datagram header is a significant error.
        length2, = unpack('<l', raw[byte_cnt:byte_cnt+LENGTH_SIZE])
        if not (length1 == length2 == byte_cnt-LENGTH_SIZE):
            raise ValueError(
                "Length of configuration datagram and number of bytes read do not match: length1: %s"
                ", length2: %s, byte_cnt: %s. Possible file corruption or format incompatibility." %
                (length1, length2, byte_cnt+LENGTH_SIZE))

        first_ping_metadata = defaultdict(list)
        trans_keys = range(1, transducer_count+1)
        trans_array = dict((key, []) for key in trans_keys)         # transducer power data
        trans_array_time = dict((key, []) for key in trans_keys)    # transducer time data
        td_f = dict.fromkeys(trans_keys)                            # transducer frequency
        td_dR = dict.fromkeys(trans_keys)                           # transducer depth measurement

        position = 0

        while raw:
            # We only care for the Sample datagrams, skip over all the other datagrams
            match = SAMPLE_MATCHER.search(raw)

            if not match:
                # Read in the next block w/ a token sized overlap
                self._stream_handle.seek(self._stream_handle.tell() - 4)
                raw = self._stream_handle.read(BLOCK_SIZE)

                # The last 4 bytes is just the length2 of the last datagram
                if len(raw) <= 4:
                    break

            # Offset by size of length value
            match_start = match.start() - LENGTH_SIZE

            # Seek to the position of the length data before the token to read into numpy array
            self._stream_handle.seek(position + match_start)

            # Read and unpack the Sample Datagram into numpy array
            sample_data = np.fromfile(self._stream_handle, dtype=sample_dtype, count=1)
            channel = sample_data['channel_number'][0]

            # Check for a valid channel number that is within the number of transducers config
            # to prevent incorrectly indexing into the dictionaries.
            # An out of bounds channel number can indicate invalid, corrupt,
            # or misaligned datagram or a reverse byte order binary data file.
            # Log warning and continue to try and process the rest of the file.
            if channel < 0 or channel > transducer_count:
                log.warn("Invalid channel: %s for transducer count: %s."
                         "Possible file corruption or format incompatibility.", channel, transducer_count)

                # Need current position in file to increment for next regex search offset
                position = self._stream_handle.tell()

                # Read the next block for regex search
                raw = self._stream_handle.read(BLOCK_SIZE)
                continue

            # Convert high and low bytes to internal time
            internal_time = (sample_data['high_date_time'][0] << 32) + sample_data['low_date_time'][0]
            # Note: Strictly sequential time tags are not guaranteed.
            trans_array_time[channel].append(internal_time)

            # Gather metadata once per transducer channel number
            if not trans_array[channel]:
                file_path = os.path.join(
                    rel_file_path, outfile + '_' + str(int(sample_data['frequency'])/1000) + 'k.png')

                first_ping_metadata[ZplscBParticleKey.FILE_TIME] = file_time
                first_ping_metadata[ZplscBParticleKey.FILE_PATH].append(file_path)
                first_ping_metadata[ZplscBParticleKey.CHANNEL].append(channel)
                first_ping_metadata[ZplscBParticleKey.TRANSDUCER_DEPTH].append(sample_data['transducer_depth'][0])
                first_ping_metadata[ZplscBParticleKey.FREQUENCY].append(sample_data['frequency'][0])
                first_ping_metadata[ZplscBParticleKey.TRANSMIT_POWER].append(sample_data['transmit_power'][0])
                first_ping_metadata[ZplscBParticleKey.PULSE_LENGTH].append(sample_data['pulse_length'][0])
                first_ping_metadata[ZplscBParticleKey.BANDWIDTH].append(sample_data['bandwidth'][0])
                first_ping_metadata[ZplscBParticleKey.SAMPLE_INTERVAL].append(sample_data['sample_interval'][0])
                first_ping_metadata[ZplscBParticleKey.SOUND_VELOCITY].append(sample_data['sound_velocity'][0])
                first_ping_metadata[ZplscBParticleKey.ABSORPTION_COEF].append(sample_data['absorption_coefficient'][0])
                first_ping_metadata[ZplscBParticleKey.TEMPERATURE].append(sample_data['temperature'][0])

                # Make only one particle for the first ping series containing data for all channels
                if channel == config_header['transducer_count']:
                    # Convert from Windows time to NTP time.
                    time = datetime(1601, 1, 1) + timedelta(microseconds=internal_time/10.0)
                    year, month, day, hour, min, sec = time.utctimetuple()[:6]
                    unix_time = calendar.timegm((year, month, day, hour, min, sec+(time.microsecond/1e6)))
                    time_stamp = ntplib.system_to_ntp_time(unix_time)

                    # Extract a particle and append it to the record buffer
                    # Note: numpy unpacked values still need to be encoded
                    particle = self._extract_sample(ZplscBInstrumentDataParticle, None,
                                                    first_ping_metadata,
                                                    time_stamp)
                    log.debug('Parsed particle: %s', particle.generate_dict())
                    self._record_buffer.append(particle)

                # Extract various calibration parameters used for generating echogram plot
                # This data doesn't change so extract it once per channel
                td_f[channel] = sample_data['frequency'][0]
                td_dR[channel] = sample_data['sound_velocity'][0] * sample_data['sample_interval'][0] / 2

            count = sample_data['count'][0]

            # Extract array of power data
            power_dtype = np.dtype([('power_data', '<i2')])     # 2 byte int (short)
            power_data = np.fromfile(self._stream_handle, dtype=power_dtype, count=count)

            # Decompress power data to dB
            trans_array[channel].append(power_data['power_data'] * 10. * np.log10(2) / 256.)

            # Read the athwartship and alongship angle measurements
            if sample_data['mode'][0] > 1:
                angle_dtype = np.dtype([('athwart', '<i1'), ('along', '<i1')])     # 1 byte ints
                angle_data = np.fromfile(self._stream_handle, dtype=angle_dtype, count=count)

            # Read and compare length1 (from beginning of datagram) to length2
            # (from the end of datagram). A mismatch can indicate an invalid, corrupt,
            # or misaligned datagram or a reverse byte order binary data file.
            # Log warning and continue to try and process the rest of the file.
            len_dtype = np.dtype([('length2', '<i4')])     # 4 byte int (long)
            length2_data = np.fromfile(self._stream_handle, dtype=len_dtype, count=1)
            if not (sample_data['length1'][0] == length2_data['length2'][0]):
                log.warn("Mismatching beginning and end length values in sample datagram: length1"
                         ": %s, length2: %s. Possible file corruption or format incompatibility."
                         , sample_data['length1'][0], length2_data['length2'][0])

            # Need current position in file to increment for next regex search offset
            position = self._stream_handle.tell()

            # Read the next block for regex search
            raw = self._stream_handle.read(BLOCK_SIZE)

        # Driver spends most of the time plotting,
        # this can take longer for more transducers so lets break out the work
        processes = []
        for channel in td_f.iterkeys():
            try:
                process = Process(target=self.generate_echogram_plot,
                                  args=(trans_array_time[channel], trans_array[channel],
                                        td_f[channel], td_dR[channel], channel,
                                        os.path.join(
                                            self.output_file_path,
                                            first_ping_metadata[ZplscBParticleKey.FILE_PATH][channel-1])))
                process.start()
                processes.append(process)

            except Exception, e:
                log.error("Error: Unable to start process: %s", e)

        for p in processes:
            p.join()

    @staticmethod
    def generate_echogram_plot(trans_array_time, trans_array, td_f, td_dR, channel, filename):
        # Generate echogram plots with sample data collected for each channel
        # Transpose array data so the sample power data is on the y-axis
        trans_array = np.transpose(trans_array)

        generate_plots(trans_array, trans_array_time, td_f, td_dR,
                       "Transducer # " + str(channel) + ": ", filename)